{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a629712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a539170",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a49a91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(df, max_samples, min_samples, column):\n",
    "    df=df.copy()\n",
    "    groups=df.groupby(column)    \n",
    "    trimmed_df = pd.DataFrame(columns = df.columns)\n",
    "    groups=df.groupby(column)\n",
    "    for label in df[column].unique(): \n",
    "        group=groups.get_group(label)\n",
    "        count=len(group)    \n",
    "        if count > max_samples:\n",
    "            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n",
    "            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "        else:\n",
    "            if count>=min_samples:\n",
    "                sampled_group=group        \n",
    "                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n",
    "    return trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90e5c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_samples(gen):\n",
    "    t_dict = gen.class_indices\n",
    "    classes = list(t_dict.keys())\n",
    "    images, labels = next(gen)\n",
    "    \n",
    "    plt.figure(figsize = (20, 20))\n",
    "    length = len(labels)\n",
    "    \n",
    "    if length<25:   #show maximum of 25 images\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    \n",
    "    for i in range(r):        \n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image=images[i] /255       \n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=12)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "104ad846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_path, test_path, max_samples, min_samples, img_size, batch_size,\n",
    "                    horizontal_flip=True, rotation_range=25, width_shift_range=.25,\n",
    "                                height_shift_range=.3, zoom_range=.4, show_images=True):\n",
    "    train_path = train_path\n",
    "    test_path = test_path\n",
    "\n",
    "    for d in [train_path, test_path]:\n",
    "        filepaths = []\n",
    "        labels = []\n",
    "        classlist = sorted(os.listdir(d))\n",
    "\n",
    "        for klass in classlist:        \n",
    "            classpath = os.path.join(d, klass)\n",
    "            flist = sorted(os.listdir(classpath))\n",
    "\n",
    "            for f in flist:\n",
    "                fpath = os.path.join(classpath,f)\n",
    "                filepaths.append(fpath)\n",
    "                labels.append(klass)\n",
    "\n",
    "        Fseries = pd.Series(filepaths, name='filepaths')\n",
    "        Lseries = pd.Series(labels, name='labels') \n",
    "\n",
    "        if d == train_path:            \n",
    "            df = pd.concat([Fseries, Lseries], axis=1)\n",
    "        else:\n",
    "            test_df = pd.concat([Fseries, Lseries], axis=1)\n",
    "\n",
    "    train_df, valid_df = train_test_split(df, train_size=.9, shuffle=True, random_state=123, stratify=df['labels']) \n",
    "\n",
    "    # get the number of classes and the images count for each class in train_df\n",
    "    classes = sorted(list(train_df['labels'].unique()))\n",
    "    class_count = len(classes)\n",
    "\n",
    "    groups = train_df.groupby('labels')\n",
    "\n",
    "\n",
    "    countlist = []\n",
    "    classlist = []\n",
    "\n",
    "    for label in sorted(list(train_df['labels'].unique())):\n",
    "        group = groups.get_group(label)\n",
    "        countlist.append(len(group))\n",
    "        classlist.append(label)\n",
    "\n",
    "    # get the classes with the minimum and maximum number of train images\n",
    "    max_value = np.max(countlist)\n",
    "    max_index = countlist.index(max_value)\n",
    "    max_class = classlist[max_index]\n",
    "    min_value = np.min(countlist)\n",
    "    min_index = countlist.index(min_value)\n",
    "    min_class = classlist[min_index]\n",
    "\n",
    "\n",
    "    # lets get the average height and width of a sample of the train images\n",
    "    ht = 0\n",
    "    wt = 0\n",
    "\n",
    "    # select 100 random samples of train_df\n",
    "    train_df_sample = train_df.sample(n=100, random_state=123,axis=0)\n",
    "\n",
    "    for i in range (len(train_df_sample)):\n",
    "        fpath = train_df_sample['filepaths'].iloc[i]\n",
    "        img = plt.imread(fpath)\n",
    "        shape = img.shape\n",
    "        ht += shape[0]\n",
    "        wt += shape[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    max_samples = max_samples\n",
    "    min_samples = min_samples\n",
    "    column='labels'\n",
    "    train_df= trim(train_df, max_samples, min_samples, column)  \n",
    "        \n",
    "        \n",
    "    \n",
    "    working_dir=r'./'\n",
    "    img_size = img_size\n",
    "    batch_size = batch_size\n",
    "\n",
    "    trgen = ImageDataGenerator(horizontal_flip=horizontal_flip, rotation_range=rotation_range, width_shift_range=width_shift_range,\n",
    "                                height_shift_range=height_shift_range, zoom_range=zoom_range)\n",
    "    t_and_v_gen = ImageDataGenerator()\n",
    "\n",
    "    msg = '{0:70s} for train generator'.format(' ')\n",
    "    print(msg, '\\r', end = '') # prints over on the same line\n",
    "\n",
    "    train_gen = trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    msg = '{0:70s} for valid generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "\n",
    "    valid_gen = t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    # for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n",
    "    # this insures that we go through all the sample in the test set exactly once.\n",
    "    length = len(test_df)\n",
    "    test_batch_size = sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
    "    test_steps = int(length/test_batch_size)\n",
    "\n",
    "    msg = '{0:70s} for test generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "\n",
    "    test_gen = t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "\n",
    "    # from the generator we can get information we will need later\n",
    "    classes = list(train_gen.class_indices.keys())\n",
    "    class_indices = list(train_gen.class_indices.values())\n",
    "    class_count = len(classes)\n",
    "    labels = test_gen.labels\n",
    "\n",
    "    print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)\n",
    "    \n",
    "    if show_images:\n",
    "        show_image_samples(train_gen)\n",
    "    \n",
    "    return train_gen, test_gen, valid_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ff48749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'D:\\Projekat 2022\\dataset\\Synthetic ASL Alphabet\\Train_Alphabet'\n",
    "test_path = 'D:\\Projekat 2022\\dataset\\Synthetic ASL Alphabet\\Test_Alphabet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64b53341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def combine_dims(a, i=0, n=1):\n",
    "  \"\"\"\n",
    "  Combines dimensions of numpy array `a`, \n",
    "  starting at index `i`,\n",
    "  and combining `n` dimensions\n",
    "  \"\"\"\n",
    "  s = list(a.shape)\n",
    "  combined = functools.reduce(lambda x,y: x*y, s[i:i+n+1])\n",
    "  return np.reshape(a, s[:i] + [combined] + s[i+n+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7099889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_samples_with_landmarks(gen):\n",
    "    \n",
    "    t_dict = gen.class_indices\n",
    "    classes = list(t_dict.keys())\n",
    "    images, labels = next(gen)\n",
    "    \n",
    "    plt.figure(figsize = (20, 20))\n",
    "    length = len(labels)\n",
    "    \n",
    "    if length<25:   #show maximum of 25 images\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    \n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(max_num_hands = 1, static_image_mode=True, min_detection_confidence = 0.3)\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    \n",
    "    for i in range(r):        \n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image=images[i].astype('uint8')\n",
    "        \n",
    "        results = hands.process(image)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for handLms in results.multi_hand_landmarks:\n",
    "                mpDraw.draw_landmarks(image, handLms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "        \n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=12)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1879315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zapisi_rezultate(METOD_NUM, EKSP_NUM, acc, loss, val_acc, val_loss):\n",
    "\n",
    "    METOD_NUM = METOD_NUM\n",
    "    EKSP_NUM = EKSP_NUM\n",
    "\n",
    "    txt_file_path = r\"./Merenja/eksp_\" + str(EKSP_NUM) + \"/\"\n",
    "    files = [(acc, 'acc.txt'), (loss, 'loss.txt'), (val_acc, 'val_acc.txt'), (val_loss, 'val_loss.txt')]\n",
    "\n",
    "    for data, file_name in files:\n",
    "\n",
    "        textfile = open(txt_file_path + file_name, \"w\")\n",
    "\n",
    "        #Brise sve iz fajla\n",
    "        with textfile as file:\n",
    "            pass\n",
    "\n",
    "        textfile = open(txt_file_path + file_name, \"w\")\n",
    "\n",
    "        for element in data:\n",
    "            textfile.write(str(element) + \"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "    subject = 'model_eksp_' + str(EKSP_NUM) \n",
    "    save_id = subject + '.h5' \n",
    "    model_save_loc = os.path.join(txt_file_path, save_id)\n",
    "    model.save(model_save_loc)\n",
    "    print ('model was saved as ' , model_save_loc ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a358e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_acc(history):\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, 'y', label = 'Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    acc_is_called = list(history.history.keys())[1]\n",
    "\n",
    "    acc = history.history[acc_is_called]\n",
    "    val_acc = history.history['val_' + acc_is_called]\n",
    "\n",
    "    plt.plot(epochs, acc, 'y', label = 'Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label = 'Validation acc')\n",
    "    plt.title('Training and validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9d86a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_keypoint_database(data_path):\n",
    "    train_x = np.load(data_path + 'train/train_x.npy')\n",
    "    train_y = np.load(data_path + 'train/train_y.npy')\n",
    "    \n",
    "    test_x = np.load(data_path + 'test/test_x.npy')\n",
    "    test_y = np.load(data_path + 'test/test_y.npy')\n",
    "    \n",
    "    valid_x = np.load(data_path + 'valid/valid_x.npy')\n",
    "    valid_y = np.load(data_path + 'valid/valid_y.npy')\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y, valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b6e6e4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_keypoint_dataset(data_path, train_x, train_y, test_x, test_y, valid_x, valid_y):\n",
    "\n",
    "        np.save(data_path + 'train/train_x', train_x)\n",
    "        np.save(data_path + 'train/train_y', train_y)\n",
    "        \n",
    "        np.save(data_path + 'test/test_x', test_x)\n",
    "        np.save(data_path + 'test/test_y', test_y)\n",
    "        \n",
    "        np.save(data_path + 'valid/valid_x', valid_x)\n",
    "        np.save(data_path + 'valid/valid_y', valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0735251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_heatmap(model, test_x, test_y):\n",
    "    \n",
    "    pred = model.predict(test_x)\n",
    "    \n",
    "    length = pred.shape[0]\n",
    "\n",
    "    pred_s = np.zeros(length)\n",
    "    test_s = np.zeros(length)\n",
    "\n",
    "    for i in range(length):\n",
    "        pred_s[i] = np.where(pred[i] == max(pred[i]))[0][0]\n",
    "        test_s[i] = np.where(test_y[i] == max(test_y[i]))[0][0]\n",
    "        \n",
    "    cm = tf.math.confusion_matrix(test_s, pred_s, NUM_OF_CLASSES)\n",
    "    \n",
    "    \n",
    "    classes = ['A','B','C','D','E','F','G','H','I','K','L','M','N','O','P','Q','R','S','T','U','V','W','X','Y']\n",
    "    class_count = len(classes)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    sns.heatmap(np.transpose(cm), annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n",
    "    plt.xticks(np.arange(class_count)+.5, classes, rotation=90)\n",
    "    plt.yticks(np.arange(class_count)+.5, classes, rotation=0)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2b62fddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_wo_valid(train_path, test_path, max_samples, min_samples, img_size, batch_size,\n",
    "                    horizontal_flip=True, rotation_range=25, width_shift_range=.25,\n",
    "                                height_shift_range=.3, zoom_range=.4, show_images=True):\n",
    "    train_path = train_path\n",
    "    test_path = test_path\n",
    "\n",
    "    for d in [train_path, test_path]:\n",
    "        filepaths = []\n",
    "        labels = []\n",
    "        classlist = sorted(os.listdir(d))\n",
    "\n",
    "        for klass in classlist:        \n",
    "            classpath = os.path.join(d, klass)\n",
    "            flist = sorted(os.listdir(classpath))\n",
    "\n",
    "            for f in flist:\n",
    "                fpath = os.path.join(classpath,f)\n",
    "                filepaths.append(fpath)\n",
    "                labels.append(klass)\n",
    "\n",
    "        Fseries = pd.Series(filepaths, name='filepaths')\n",
    "        Lseries = pd.Series(labels, name='labels') \n",
    "\n",
    "        if d == train_path:            \n",
    "            df = pd.concat([Fseries, Lseries], axis=1)\n",
    "        else:\n",
    "            test_df = pd.concat([Fseries, Lseries], axis=1)\n",
    "\n",
    "    train_df = df \n",
    "\n",
    "    # get the number of classes and the images count for each class in train_df\n",
    "    classes = sorted(list(train_df['labels'].unique()))\n",
    "    class_count = len(classes)\n",
    "    \n",
    "    groups = train_df.groupby('labels')\n",
    "\n",
    "    countlist = []\n",
    "    classlist = []\n",
    "\n",
    "    for label in sorted(list(train_df['labels'].unique())):\n",
    "        group = groups.get_group(label)\n",
    "        countlist.append(len(group))\n",
    "        classlist.append(label)\n",
    "\n",
    "    # get the classes with the minimum and maximum number of train images\n",
    "    max_value = np.max(countlist)\n",
    "    max_index = countlist.index(max_value)\n",
    "    max_class = classlist[max_index]\n",
    "    min_value = np.min(countlist)\n",
    "    min_index = countlist.index(min_value)\n",
    "    min_class = classlist[min_index]\n",
    "\n",
    "\n",
    "    # lets get the average height and width of a sample of the train images\n",
    "    ht = 0\n",
    "    wt = 0\n",
    "\n",
    "    # select 100 random samples of train_df\n",
    "    train_df_sample = train_df.sample(n=100, random_state=123,axis=0)\n",
    "\n",
    "    for i in range (len(train_df_sample)):\n",
    "        fpath = train_df_sample['filepaths'].iloc[i]\n",
    "        img = plt.imread(fpath)\n",
    "        shape = img.shape\n",
    "        ht += shape[0]\n",
    "        wt += shape[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    max_samples = max_samples\n",
    "    min_samples = min_samples\n",
    "    column='labels'\n",
    "    train_df= trim(train_df, max_samples, min_samples, column)  \n",
    "        \n",
    "        \n",
    "    \n",
    "    working_dir=r'./'\n",
    "    img_size = img_size\n",
    "    batch_size = batch_size\n",
    "\n",
    "    trgen = ImageDataGenerator(horizontal_flip=horizontal_flip, rotation_range=rotation_range, width_shift_range=width_shift_range,\n",
    "                                height_shift_range=height_shift_range, zoom_range=zoom_range)\n",
    "    t_and_v_gen = ImageDataGenerator()\n",
    "\n",
    "    msg = '{0:70s} for train generator'.format(' ')\n",
    "    print(msg, '\\r', end = '') # prints over on the same line\n",
    "    \n",
    "    \n",
    "    \n",
    "    train_gen = trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "    ##msg = '{0:70s} for valid generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "\n",
    "#     valid_gen = t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "#                                        class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    # for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n",
    "    # this insures that we go through all the sample in the test set exactly once.\n",
    "    length = len(test_df)\n",
    "    test_batch_size = sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
    "    test_steps = int(length/test_batch_size)\n",
    "\n",
    "    msg = '{0:70s} for test generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "    \n",
    "    print(\"pusi kurac\")\n",
    "    print(test_df)\n",
    "    \n",
    "    #test_gen = t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col= 'labels', target_size=img_size,\n",
    "                                       #class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "\n",
    "    # from the generator we can get information we will need later\n",
    "    classes = list(train_gen.class_indices.keys())\n",
    "    class_indices = list(train_gen.class_indices.values())\n",
    "    class_count = len(classes)\n",
    "    labels = test_gen.labels\n",
    "\n",
    "    print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)\n",
    "    \n",
    "    if show_images:\n",
    "        show_image_samples(train_gen)\n",
    "    \n",
    "    return train_gen, test_gen#, valid_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16e05170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_single_dataset(df_path, max_samples, min_samples, img_size, batch_size):\n",
    "    \n",
    "    train_path = df_path\n",
    "    \n",
    "    d = train_path\n",
    "    \n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    classlist = sorted(os.listdir(d))\n",
    "\n",
    "    for klass in classlist:        \n",
    "        classpath = os.path.join(d, klass)\n",
    "        flist = sorted(os.listdir(classpath))\n",
    "\n",
    "        for f in flist:\n",
    "            fpath = os.path.join(classpath,f)\n",
    "            filepaths.append(fpath)\n",
    "            labels.append(klass)\n",
    "\n",
    "    Fseries = pd.Series(filepaths, name='filepaths')\n",
    "    Lseries = pd.Series(labels, name='labels')\n",
    "    \n",
    "    train_df = pd.concat([Fseries, Lseries], axis=1)\n",
    "    \n",
    "    classes = sorted(list(train_df['labels'].unique()))\n",
    "    class_count = len(classes)\n",
    "    \n",
    "    groups = train_df.groupby('labels')\n",
    "    \n",
    "    countlist = []\n",
    "    classlist = []\n",
    "    \n",
    "    for label in sorted(list(train_df['labels'].unique())):\n",
    "        group = groups.get_group(label)\n",
    "        countlist.append(len(group))\n",
    "        classlist.append(label)\n",
    "        \n",
    "    # get the classes with the minimum and maximum number of train images\n",
    "    max_value = np.max(countlist)\n",
    "    max_index = countlist.index(max_value)\n",
    "    max_class = classlist[max_index]\n",
    "    min_value = np.min(countlist)\n",
    "    min_index = countlist.index(min_value)\n",
    "    min_class = classlist[min_index]\n",
    "    \n",
    "    # lets get the average height and width of a sample of the train images\n",
    "    ht = 0\n",
    "    wt = 0\n",
    "\n",
    "    # select 100 random samples of train_df\n",
    "    train_df_sample = train_df.sample(n=100, random_state=123,axis=0)\n",
    "\n",
    "    for i in range (len(train_df_sample)):\n",
    "        fpath = train_df_sample['filepaths'].iloc[i]\n",
    "        img = plt.imread(fpath)\n",
    "        shape = img.shape\n",
    "        ht += shape[0]\n",
    "        wt += shape[1]    \n",
    "        \n",
    "    max_samples = max_samples\n",
    "    min_samples = min_samples\n",
    "    column='labels'\n",
    "    train_df= trim(train_df, max_samples, min_samples, column) \n",
    "    \n",
    "    trgen = ImageDataGenerator()\n",
    "    \n",
    "    train_gen = trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
    "    \n",
    "    classes = list(train_gen.class_indices.keys())\n",
    "    class_indices = list(train_gen.class_indices.values())\n",
    "    class_count = len(classes)\n",
    "    labels = train_gen.labels\n",
    "    \n",
    "    return train_gen\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78a683af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hand_border(points, buffer):\n",
    "    \n",
    "    x = points[:, 0]\n",
    "    y = points[:, 1]\n",
    "    \n",
    "    min_x = nn(int(np.min(x) - buffer))\n",
    "    max_x = nn(int(np.max(x) + buffer))\n",
    "\n",
    "    min_y = nn(int(np.min(y) - buffer))\n",
    "    max_y = nn(int(np.max(y) + buffer))\n",
    "    \n",
    "    return [min_x, max_x, min_y, max_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1b3edd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cut_n_resize(img, border, dimensions):\n",
    "    \n",
    "    #print(\"border = \", border)\n",
    "    cropped_img = img[border[2]:border[3], border[0]:border[1]]\n",
    "\n",
    "    resized_img = cv2.resize(cropped_img, dimensions)\n",
    "    \n",
    "    return resized_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa1a0bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn(a, upper_treshold=np.inf):\n",
    "  if a < 0:\n",
    "    return 0\n",
    "  if a >= upper_treshold:\n",
    "    return upper_treshold - 1\n",
    "  return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac763cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_central_color_range(img, keypoints):\n",
    "    \n",
    "    lower_range = np.array([255, 255, 255])\n",
    "    upper_range = np.array([0, 0, 0])\n",
    "    \n",
    "    for i in range(21):\n",
    "        for j in range(3):    \n",
    "            x = nn(int(keypoints[i, 0]), img.shape[0])\n",
    "            y = nn(int(keypoints[i, 1]), img.shape[1])\n",
    "            #print(lower_range[j])\n",
    "            lower_range[j] = min(img[y, x, j], lower_range[j])\n",
    "            upper_range[j] = max(img[y, x, j], upper_range[j])\n",
    "            \n",
    "    return lower_range, upper_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "503883bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_binarised_image_samples(gen,\n",
    "                                 buffer,\n",
    "                                 dimensions = (128, 128),\n",
    "                                 lower_range_tightness = 0,\n",
    "                                 upper_range_tightness = 0):\n",
    "    \n",
    "    t_dict = gen.class_indices\n",
    "    classes = list(t_dict.keys())\n",
    "    images, labels = next(gen)\n",
    "    \n",
    "    plt.figure(figsize = (20, 20))\n",
    "    length = len(labels)\n",
    "    \n",
    "    if length<25:   #show maximum of 25 images\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    \n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(max_num_hands = 1, static_image_mode=True, min_detection_confidence = 0.1)\n",
    "    \n",
    "    for i in range(r):\n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image=images[i].astype('uint8')\n",
    "            \n",
    "        mask = get_hand_mask(image,\n",
    "                              buffer,\n",
    "                              dimensions,\n",
    "                              lower_range_tightness,\n",
    "                              upper_range_tightness,\n",
    "                            hands)\n",
    "        \n",
    "        plt.imshow(mask)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=12)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc45d475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_kNN_database(generator,\n",
    "                          num_of_samples,\n",
    "                          buffer = 20,\n",
    "                          dimensions = (200, 200),\n",
    "                          lower_range_tightness = 0,\n",
    "                          upper_range_tightness = 0,\n",
    "                         num_of_rows = 10):\n",
    "    \n",
    "    \n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(max_num_hands = 1, static_image_mode=True, min_detection_confidence = 0.3)\n",
    "    \n",
    "    data = np.zeros((num_of_samples * 24, num_of_rows * num_of_rows))\n",
    "    lb_count = np.zeros(24)\n",
    "    labels = []\n",
    "    \n",
    "    samples = 0\n",
    "    sector_len = dimensions[0] // num_of_rows\n",
    "    \n",
    "    for batch in generator:\n",
    "        for i in range(batch[0].shape[0]):\n",
    "            \n",
    "            image = batch[0][i].astype('uint8')\n",
    "            label = batch[1][i] \n",
    "            label_name = np.where(label == max(label))[0][0]\n",
    "            \n",
    "            if lb_count[label_name] >= num_of_samples:\n",
    "                continue\n",
    "            \n",
    "            mask = get_hand_mask(image,\n",
    "                                  buffer,\n",
    "                                  dimensions,\n",
    "                                  lower_range_tightness,\n",
    "                                  upper_range_tightness,\n",
    "                                hands)\n",
    "            for i in range (num_of_rows):\n",
    "                for j in range(num_of_rows):\n",
    "                    data[samples][i * num_of_rows + j] = np.sum(mask[i*sector_len : (i+1)*sector_len, j*sector_len : (j+1)*sector_len]) / (sector_len**2 * 255)\n",
    "                    \n",
    "            labels.append(label)\n",
    "            lb_count[label_name] += 1\n",
    "            samples += 1\n",
    "            message = str(samples)\n",
    "            sys.stdout.write('\\r'+ \"Generated  \" + message + \"  samples out of  \" + str(num_of_samples * 24) + \"  samples\")\n",
    "\n",
    "            if samples >= num_of_samples * 24:\n",
    "                break\n",
    "                \n",
    "        if samples >= num_of_samples * 24:\n",
    "                break\n",
    "    \n",
    "    sys.stdout.write('\\r'+ \"DONE: Generated  \" + message + \"  samples\")\n",
    "    exit_labels = np.array(labels)\n",
    "    \n",
    "    return data, exit_labels     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c09dfc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def organise_hand_keypoints(img, results):\n",
    "    \n",
    "    data = np.zeros((21, 2))\n",
    "    img_shape = img.shape\n",
    "    \n",
    "    for handLms in results.multi_hand_landmarks:   \n",
    "        for id, lm in enumerate(handLms.landmark):\n",
    "            data[id, 0] = lm.x * img_shape[0]\n",
    "            data[id, 1] = lm.y * img_shape[1]\n",
    "            \n",
    "    return data           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "394c1472",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand_mask(image,\n",
    "                  buffer,\n",
    "                  dimensions = (128, 128),\n",
    "                  lower_range_tightness = 0,\n",
    "                  upper_range_tightness = 0,\n",
    "                 hands = mp.solutions.hands.Hands(max_num_hands = 1, static_image_mode=True, min_detection_confidence = 0.1)):\n",
    "\n",
    "    image_cut = np.zeros((128, 128, 3))\n",
    "    mask = image_cut.copy()\n",
    "\n",
    "    results = hands.process(image)\n",
    "    if results.multi_hand_landmarks:\n",
    "\n",
    "        keypoints = organise_hand_keypoints(image, results)\n",
    "        image_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "        #color = central_color(image, keypoints)\n",
    "        lower_range, upper_range = find_central_color_range(image_hsv, keypoints)\n",
    "        #print(color)\n",
    "\n",
    "        border = hand_border(keypoints, buffer)\n",
    "        image_cut = cut_n_resize(image, border, dimensions)\n",
    "        image_cut_hsv = cv2.cvtColor(image_cut, cv2.COLOR_RGB2HSV)\n",
    "\n",
    "        for j in range(len(lower_range)):\n",
    "            lower_range[j] *= (1 +  lower_range_tightness)\n",
    "            upper_range[j] *= (1 - upper_range_tightness)\n",
    "\n",
    "        mask = cv2.inRange(np.array(image_cut_hsv), lower_range, upper_range)\n",
    "\n",
    "        kernel1 = np.ones((5, 5), np.uint8) \n",
    "        kernel2 = np.ones((3, 3), np.uint8) \n",
    "\n",
    "        mask = cv2.erode(mask, kernel1, iterations = 1)\n",
    "        mask = cv2.dilate(mask, kernel1, iterations = 1)\n",
    "\n",
    "        mask = cv2.dilate(mask, kernel2, iterations = 1)\n",
    "        mask = cv2.erode(mask, kernel2, iterations = 1)\n",
    "        \n",
    "    return mask \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b37fb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbbaff46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53629bff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6f44fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4422f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
