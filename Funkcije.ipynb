{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a629712",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import seaborn as sns\n",
    "sns.set_style('darkgrid')\n",
    "import shutil\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.data import Dataset\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a49a91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trim(df, max_samples, min_samples, column):\n",
    "    df=df.copy()\n",
    "    groups=df.groupby(column)    \n",
    "    trimmed_df = pd.DataFrame(columns = df.columns)\n",
    "    groups=df.groupby(column)\n",
    "    for label in df[column].unique(): \n",
    "        group=groups.get_group(label)\n",
    "        count=len(group)    \n",
    "        if count > max_samples:\n",
    "            sampled_group=group.sample(n=max_samples, random_state=123,axis=0)\n",
    "            trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "        else:\n",
    "            if count>=min_samples:\n",
    "                sampled_group=group        \n",
    "                trimmed_df=pd.concat([trimmed_df, sampled_group], axis=0)\n",
    "    print('after trimming, the maximum samples in any class is now ',max_samples, ' and the minimum samples in any class is ', min_samples)\n",
    "    return trimmed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e5c956",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_samples(gen):\n",
    "    t_dict = gen.class_indices\n",
    "    classes = list(t_dict.keys())\n",
    "    images, labels = next(gen)\n",
    "    \n",
    "    plt.figure(figsize = (20, 20))\n",
    "    length = len(labels)\n",
    "    \n",
    "    if length<25:   #show maximum of 25 images\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    \n",
    "    for i in range(r):        \n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image=images[i] /255       \n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=12)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "104ad846",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_path, test_path, max_samples, min_samples, img_size, batch_size,\n",
    "                    horizontal_flip=True, rotation_range=25, width_shift_range=.25,\n",
    "                                height_shift_range=.3, zoom_range=.4):\n",
    "    train_path = train_path\n",
    "    test_path = test_path\n",
    "\n",
    "    for d in [train_path, test_path]:\n",
    "        filepaths = []\n",
    "        labels = []\n",
    "        classlist = sorted(os.listdir(d))\n",
    "\n",
    "        for klass in classlist:        \n",
    "            classpath = os.path.join(d, klass)\n",
    "            flist = sorted(os.listdir(classpath))\n",
    "\n",
    "            for f in flist:\n",
    "                fpath = os.path.join(classpath,f)\n",
    "                filepaths.append(fpath)\n",
    "                labels.append(klass)\n",
    "\n",
    "        Fseries = pd.Series(filepaths, name='filepaths')\n",
    "        Lseries = pd.Series(labels, name='labels') \n",
    "\n",
    "        if d == train_path:            \n",
    "            df = pd.concat([Fseries, Lseries], axis=1)\n",
    "        else:\n",
    "            test_df = pd.concat([Fseries, Lseries], axis=1)\n",
    "\n",
    "    train_df, valid_df = train_test_split(df, train_size=.9, shuffle=True, random_state=123, stratify=df['labels']) \n",
    "\n",
    "    # get the number of classes and the images count for each class in train_df\n",
    "    classes = sorted(list(train_df['labels'].unique()))\n",
    "    class_count = len(classes)\n",
    "\n",
    "    groups = train_df.groupby('labels')\n",
    "\n",
    "\n",
    "    countlist = []\n",
    "    classlist = []\n",
    "\n",
    "    for label in sorted(list(train_df['labels'].unique())):\n",
    "        group = groups.get_group(label)\n",
    "        countlist.append(len(group))\n",
    "        classlist.append(label)\n",
    "\n",
    "    # get the classes with the minimum and maximum number of train images\n",
    "    max_value = np.max(countlist)\n",
    "    max_index = countlist.index(max_value)\n",
    "    max_class = classlist[max_index]\n",
    "    min_value = np.min(countlist)\n",
    "    min_index = countlist.index(min_value)\n",
    "    min_class = classlist[min_index]\n",
    "\n",
    "\n",
    "    # lets get the average height and width of a sample of the train images\n",
    "    ht = 0\n",
    "    wt = 0\n",
    "\n",
    "    # select 100 random samples of train_df\n",
    "    train_df_sample = train_df.sample(n=100, random_state=123,axis=0)\n",
    "\n",
    "    for i in range (len(train_df_sample)):\n",
    "        fpath = train_df_sample['filepaths'].iloc[i]\n",
    "        img = plt.imread(fpath)\n",
    "        shape = img.shape\n",
    "        ht += shape[0]\n",
    "        wt += shape[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "    max_samples = max_samples\n",
    "    min_samples = min_samples\n",
    "    column='labels'\n",
    "    train_df= trim(train_df, max_samples, min_samples, column)  \n",
    "        \n",
    "        \n",
    "    \n",
    "    working_dir=r'./'\n",
    "    img_size = img_size\n",
    "    batch_size = batch_size\n",
    "\n",
    "    trgen = ImageDataGenerator(horizontal_flip=horizontal_flip, rotation_range=rotation_range, width_shift_range=width_shift_range,\n",
    "                                height_shift_range=height_shift_range, zoom_range=zoom_range)\n",
    "    t_and_v_gen = ImageDataGenerator()\n",
    "\n",
    "    msg = '{0:70s} for train generator'.format(' ')\n",
    "    print(msg, '\\r', end = '') # prints over on the same line\n",
    "\n",
    "    train_gen = trgen.flow_from_dataframe(train_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=True, batch_size=batch_size)\n",
    "\n",
    "    msg = '{0:70s} for valid generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "\n",
    "    valid_gen = t_and_v_gen.flow_from_dataframe(valid_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=batch_size)\n",
    "\n",
    "\n",
    "    # for the test_gen we want to calculate the batch size and test steps such that batch_size X test_steps= number of samples in test set\n",
    "    # this insures that we go through all the sample in the test set exactly once.\n",
    "    length = len(test_df)\n",
    "    test_batch_size = sorted([int(length/n) for n in range(1,length+1) if length % n ==0 and length/n<=80],reverse=True)[0]  \n",
    "    test_steps = int(length/test_batch_size)\n",
    "\n",
    "    msg = '{0:70s} for test generator'.format(' ')\n",
    "    print(msg, '\\r', end='') # prints over on the same line\n",
    "\n",
    "    test_gen = t_and_v_gen.flow_from_dataframe(test_df, x_col='filepaths', y_col='labels', target_size=img_size,\n",
    "                                       class_mode='categorical', color_mode='rgb', shuffle=False, batch_size=test_batch_size)\n",
    "\n",
    "    # from the generator we can get information we will need later\n",
    "    classes = list(train_gen.class_indices.keys())\n",
    "    class_indices = list(train_gen.class_indices.values())\n",
    "    class_count = len(classes)\n",
    "    labels = test_gen.labels\n",
    "\n",
    "    print ( 'test batch size: ' ,test_batch_size, '  test steps: ', test_steps, ' number of classes : ', class_count)\n",
    "    \n",
    "    show_image_samples(train_gen)\n",
    "    \n",
    "    return train_gen, test_gen, valid_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ff48749",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'D:\\Projekat 2022\\dataset\\Synthetic ASL Alphabet\\Train_Alphabet'\n",
    "test_path = 'D:\\Projekat 2022\\dataset\\Synthetic ASL Alphabet\\Test_Alphabet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7fb531a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keypoint_df(generator, num_of_samples):\n",
    "    \n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(max_num_hands = 1, static_image_mode=True, min_detection_confidence = 0.3)\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    \n",
    "    x = np.zeros((num_of_samples, 21))\n",
    "    y = np.zeros((num_of_samples, 21))\n",
    "    z = np.zeros((num_of_samples, 21))\n",
    "    labels = []\n",
    "    \n",
    "    samples = 0\n",
    "    \n",
    "    for batch in generator:\n",
    "        for i in range(batch[0].shape[0]):\n",
    "            img = batch[0][i].astype('uint8')\n",
    "            label = batch[1][i] \n",
    "            \n",
    "            results = hands.process(img)\n",
    "            \n",
    "            if results.multi_hand_landmarks:\n",
    "                for handLms in results.multi_hand_landmarks:\n",
    "                    \n",
    "                    landmarks_x = np.zeros(21)\n",
    "                    landmarks_y = np.zeros(21)\n",
    "                    landmarks_z = np.zeros(21)\n",
    "                    \n",
    "                    for id, lm in enumerate(handLms.landmark):                           \n",
    "                            \n",
    "                        landmarks_x[id] = lm.x\n",
    "                        landmarks_y[id] = lm.y\n",
    "                        landmarks_z[id] = lm.z\n",
    "                        \n",
    "                x[samples] = landmarks_x\n",
    "                y[samples] = landmarks_y\n",
    "                z[samples] = landmarks_z\n",
    "                labels.append(label)\n",
    "                samples += 1\n",
    "                b = str(samples)\n",
    "                sys.stdout.write('\\r'+ \"Generated  \" + b + \"  samples out of  \" + str(num_of_samples) + \"  samples\")\n",
    "\n",
    "                \n",
    "                if samples >= num_of_samples:\n",
    "                    break\n",
    "\n",
    "        if samples >= num_of_samples:\n",
    "            break\n",
    "    \n",
    "    sys.stdout.write('\\r'+ \"DONE: Generated  \" + b + \"  samples\")\n",
    "    exit_labels = np.array(labels)\n",
    "    \n",
    "    return x, y, z, exit_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bc9e861",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_keypoint_sequential(generator, num_of_samples, include_z = False):\n",
    "    \n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(max_num_hands = 1, static_image_mode=True, min_detection_confidence = 0.3)\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    " \n",
    "    n = 2\n",
    "    if include_z:\n",
    "        n = 3\n",
    "    \n",
    "    data = np.zeros((num_of_samples, 21 * n))\n",
    "    labels = []\n",
    "    \n",
    "    samples = 0\n",
    "    \n",
    "    for batch in generator:\n",
    "        for i in range(batch[0].shape[0]):\n",
    "            img = batch[0][i].astype('uint8')\n",
    "            label = batch[1][i] \n",
    "            \n",
    "            results = hands.process(img)\n",
    "            \n",
    "            if results.multi_hand_landmarks:\n",
    "                for handLms in results.multi_hand_landmarks:\n",
    "                    \n",
    "                    i = 0\n",
    "                    \n",
    "                    for id, lm in enumerate(handLms.landmark):\n",
    "                        \n",
    "                        data[samples][i] = lm.x\n",
    "                        i += 1\n",
    "                        data[samples][i] = lm.y\n",
    "                        i += 1\n",
    "                        if include_z: \n",
    "                            data[samples][i] = lm.y\n",
    "                            i += 1\n",
    "                            \n",
    "                labels.append(label)\n",
    "                samples += 1\n",
    "                message = str(samples)\n",
    "                sys.stdout.write('\\r'+ \"Generated  \" + message + \"  samples out of  \" + str(num_of_samples) + \"  samples\")\n",
    "                #print(\"Generated  \", samples, \"  samples\")\n",
    "                \n",
    "                if samples >= num_of_samples:\n",
    "                    break\n",
    "\n",
    "        if samples >= num_of_samples:\n",
    "            break\n",
    "    \n",
    "    sys.stdout.write('\\r'+ \"DONE: Generated  \" + message + \"  samples\")\n",
    "    exit_labels = np.array(labels)\n",
    "    \n",
    "    return data, exit_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64b53341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "def combine_dims(a, i=0, n=1):\n",
    "  \"\"\"\n",
    "  Combines dimensions of numpy array `a`, \n",
    "  starting at index `i`,\n",
    "  and combining `n` dimensions\n",
    "  \"\"\"\n",
    "  s = list(a.shape)\n",
    "  combined = functools.reduce(lambda x,y: x*y, s[i:i+n+1])\n",
    "  return np.reshape(a, s[:i] + [combined] + s[i+n+1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57be8d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_keypoint_database(num_of_train_samples, num_of_test_samples, num_of_valid_samples):\n",
    "    \n",
    "    num_of_train_samples = num_of_train_samples\n",
    "    num_of_test_samples = num_of_test_samples\n",
    "    num_of_valid_samples = num_of_valid_samples\n",
    "    \n",
    "    new_train_df = generate_keypoint_df(train_gen, num_of_train_samples)\n",
    "    new_test_df = generate_keypoint_df(train_gen, num_of_test_samples)\n",
    "    new_valid_df = generate_keypoint_df(train_gen, num_of_valid_samples)\n",
    "    \n",
    "    train_db = new_train_df\n",
    "    test_db = new_test_df\n",
    "    valid_db = new_valid_df\n",
    "    \n",
    "    train_x = np.array([train_db[0], train_db[1]])\n",
    "    train_y = np.array(train_db[3])\n",
    "    test_x = np.array([test_db[0], test_db[1]])\n",
    "    test_y = np.array(test_db[3])\n",
    "    valid_x = np.array([valid_db[0], valid_db[1]])\n",
    "    valid_y = np.array(valid_db[3])\n",
    "    \n",
    "    train_x = np.transpose(train_x, (1, 0, 2))\n",
    "    test_x = np.transpose(test_x, (1, 0, 2))\n",
    "    valid_x = np.transpose(valid_x, (1, 0, 2))\n",
    "    \n",
    "    train_x = combine_dims(train_x, 1)\n",
    "    test_x = combine_dims(test_x, 1)\n",
    "    valid_x = combine_dims(valid_x, 1)\n",
    "    \n",
    "    return train_x, train_y, test_x, test_y, valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7099889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_samples_with_landmarks(gen):\n",
    "    t_dict = gen.class_indices\n",
    "    classes = list(t_dict.keys())\n",
    "    images, labels = next(gen)\n",
    "    \n",
    "    plt.figure(figsize = (20, 20))\n",
    "    length = len(labels)\n",
    "    \n",
    "    if length<25:   #show maximum of 25 images\n",
    "        r=length\n",
    "    else:\n",
    "        r=25\n",
    "    \n",
    "    mpHands = mp.solutions.hands\n",
    "    hands = mpHands.Hands(max_num_hands = 1, static_image_mode=True, min_detection_confidence = 0.3)\n",
    "    mpDraw = mp.solutions.drawing_utils\n",
    "    \n",
    "    for i in range(r):        \n",
    "        plt.subplot(5, 5, i + 1)\n",
    "        image=images[i].astype('uint8')\n",
    "        \n",
    "        results = hands.process(image)\n",
    "        if results.multi_hand_landmarks:\n",
    "            for handLms in results.multi_hand_landmarks:\n",
    "                mpDraw.draw_landmarks(image, handLms, mpHands.HAND_CONNECTIONS)\n",
    "\n",
    "        \n",
    "        plt.imshow(image)\n",
    "        index=np.argmax(labels[i])\n",
    "        class_name=classes[index]\n",
    "        plt.title(class_name, color='blue', fontsize=12)\n",
    "        plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1879315c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zapisi_rezultate(METOD_NUM, EKSP_NUM, acc, loss, val_acc, val_loss):\n",
    "\n",
    "    METOD_NUM = METOD_NUM\n",
    "    EKSP_NUM = EKSP_NUM\n",
    "\n",
    "    txt_file_path = \"D:/Projekat 2022/Metod \" + str(METOD_NUM) + \"/Merenja/eksp_\" + str(EKSP_NUM) + \"/\"\n",
    "    files = [(acc, 'acc.txt'), (loss, 'loss.txt'), (val_acc, 'val_acc.txt'), (val_loss, 'val_loss.txt')]\n",
    "\n",
    "    for data, file_name in files:\n",
    "\n",
    "        textfile = open(txt_file_path + file_name, \"w\")\n",
    "\n",
    "        #Brise sve iz fajla\n",
    "        with textfile as file:\n",
    "            pass\n",
    "\n",
    "        textfile = open(txt_file_path + file_name, \"w\")\n",
    "\n",
    "        for element in data:\n",
    "            textfile.write(str(element) + file_name + \"\\n\")\n",
    "        textfile.close()\n",
    "\n",
    "    subject = 'model_eksp_' + str(EKSP_NUM) \n",
    "    save_id = subject + '.h5' \n",
    "    model_save_loc = os.path.join(txt_file_path, save_id)\n",
    "    model.save(model_save_loc)\n",
    "    print ('model was saved as ' , model_save_loc ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a358e251",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_and_acc(history):\n",
    "\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(1, len(loss) + 1)\n",
    "\n",
    "    plt.plot(epochs, loss, 'y', label = 'Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label = 'Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    acc_is_called = list(history.history.keys())[1]\n",
    "\n",
    "    acc = history.history[acc_is_called]\n",
    "    val_acc = history.history['val_' + acc_is_called]\n",
    "\n",
    "    plt.plot(epochs, acc, 'y', label = 'Training acc')\n",
    "    plt.plot(epochs, val_acc, 'r', label = 'Validation acc')\n",
    "    plt.title('Training and validation acc')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Acc')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87fbcfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
